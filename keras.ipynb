{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "major-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "correct-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題1 keras_tutorial.ipynbで実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quarterly-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題3 ris 2値分類\n",
    "\n",
    "# データセットの読み込み\n",
    "df = pd.read_csv(\"data/Iris.csv\")\n",
    "\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "\n",
    "# NumPy 配列に変換\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# ラベルを数値に変換\n",
    "y[y == \"Iris-versicolor\"] = 0\n",
    "y[y == \"Iris-virginica\"] = 1\n",
    "y = y.astype(np.int64)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "accurate-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(4),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(150, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "preliminary-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "institutional-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smart-wallet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.5312\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5312\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.5625\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.8125\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.9062\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7969\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.6562\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5477 - accuracy: 0.7656\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.8594\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.9375\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.9531\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.9062\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9219\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.9219\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.9531\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.9531\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.9375\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.9375\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.9375\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.9531\n",
      "CPU times: user 545 ms, sys: 60.1 ms, total: 605 ms\n",
      "Wall time: 545 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1614fc100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "corrected-projector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.3986 - accuracy: 0.9000 - 125ms/epoch - 125ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3985688090324402, 0.8999999761581421]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "selective-capability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.4543973e-01  2.2222129e-01]\n",
      " [-1.5889244e-01  1.1105576e+00]\n",
      " [ 9.6498692e-01  1.6922157e-01]\n",
      " [-5.0018513e-01  1.4206216e+00]\n",
      " [ 8.9202002e-02  9.2801642e-01]\n",
      " [-2.5421178e-01  1.1948478e+00]\n",
      " [ 5.6961352e-01  3.8500720e-01]\n",
      " [ 2.4421419e-01  6.7056310e-01]\n",
      " [-4.1538289e-01  1.2752447e+00]\n",
      " [ 1.7217284e-01  8.1322753e-01]\n",
      " [-2.3437351e-01  1.0875815e+00]\n",
      " [-2.3719572e-01  1.0304973e+00]\n",
      " [-3.8420421e-01  1.2130740e+00]\n",
      " [ 6.3074440e-01  3.5484037e-01]\n",
      " [ 1.0710127e+00 -1.6933444e-01]\n",
      " [ 9.0247881e-01  1.6835649e-02]\n",
      " [ 2.4368589e-01  6.3810068e-01]\n",
      " [ 1.1846950e+00 -7.7705294e-02]\n",
      " [ 7.3714741e-04  8.4149599e-01]\n",
      " [ 1.0272990e+00  6.7061245e-02]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6509502 , 0.34904984],\n",
       "       [0.21935143, 0.7806486 ],\n",
       "       [0.6890679 , 0.31093207],\n",
       "       [0.12777163, 0.87222844],\n",
       "       [0.30178455, 0.6982155 ],\n",
       "       [0.19014633, 0.8098536 ],\n",
       "       [0.5460209 , 0.45397905],\n",
       "       [0.39499846, 0.60500145],\n",
       "       [0.15569332, 0.84430665],\n",
       "       [0.34500816, 0.65499187],\n",
       "       [0.2104932 , 0.78950673],\n",
       "       [0.21965241, 0.7803476 ],\n",
       "       [0.16836238, 0.8316376 ],\n",
       "       [0.56854177, 0.43145823],\n",
       "       [0.77562445, 0.22437558],\n",
       "       [0.7079902 , 0.29200974],\n",
       "       [0.40265498, 0.597345  ],\n",
       "       [0.77943903, 0.22056098],\n",
       "       [0.301375  , 0.698625  ],\n",
       "       [0.72316945, 0.27683058]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(X_test).numpy()\n",
    "print(pred)\n",
    "# 確率に変換\n",
    "pred = tf.nn.softmax(pred).numpy()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "round-winning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0]\n",
      "[0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3つ不正解がある'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.argmax(pred, axis=1))\n",
    "print(y_test.reshape(len(y_test)))\n",
    "display(\"3つ不正解がある\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bizarre-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題4 iris 3種類分類\n",
    "\n",
    "# データセットの読み込み\n",
    "df = pd.read_csv(\"data/Iris.csv\")\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "\n",
    "# NumPy 配列に変換\n",
    "X = np.array(X)\n",
    "\n",
    "y = np.array(pd.get_dummies(df[\"Species\"]))\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "novel-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(4),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(150, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])\n",
    "# 損失関数 (OHEしてない場合使う)\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# OHEしてる場合はこちら\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "# 以下でもよい\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "subjective-parameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.1380 - accuracy: 0.2812 - val_loss: 0.9665 - val_accuracy: 0.3750\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9436 - accuracy: 0.3646 - val_loss: 0.8459 - val_accuracy: 0.7083\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8184 - accuracy: 0.7708 - val_loss: 0.7698 - val_accuracy: 0.7083\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7424 - accuracy: 0.7812 - val_loss: 0.6709 - val_accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6503 - accuracy: 0.7396 - val_loss: 0.6111 - val_accuracy: 0.7083\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5920 - accuracy: 0.6875 - val_loss: 0.5530 - val_accuracy: 0.7083\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5259 - accuracy: 0.6979 - val_loss: 0.4992 - val_accuracy: 0.7083\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.8542 - val_loss: 0.4704 - val_accuracy: 0.7083\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.8646 - val_loss: 0.4448 - val_accuracy: 0.7083\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4033 - accuracy: 0.8542 - val_loss: 0.4240 - val_accuracy: 0.7917\n",
      "CPU times: user 748 ms, sys: 53.9 ms, total: 802 ms\n",
      "Wall time: 728 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161d3afd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, batch_size=30, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adapted-cornwall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.4320 - accuracy: 0.7667 - 16ms/epoch - 16ms/step\n",
      "[2 1 0 2 0 2 0 1 2 1 2 1 2 2 2 0 2 2 0 0 2 2 0 0 2 0 0 1 1 0]\n",
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1と2二体する誤分類が多いように見える'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)\n",
    "pred = model(X_test).numpy()\n",
    "# print(pred)\n",
    "# 確率に変換\n",
    "pred = tf.nn.softmax(pred).numpy()\n",
    "# print(pred)\n",
    "print(np.argmax(pred, axis=1))\n",
    "print(np.argmax(y_test, axis=1))\n",
    "display(\"1と2二体する誤分類が多いように見える\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "extra-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題5 houe Price\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# データセットの読み込み\n",
    "df = pd.read_csv(\"data/housing/train.csv\")\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "\n",
    "# NumPy 配列に変換\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "y = y[:, np.newaxis]\n",
    "\n",
    "# 標準化\n",
    "standardScaler_y = StandardScaler()\n",
    "standardScaler_X = StandardScaler()\n",
    "y = standardScaler_y.fit_transform(y)\n",
    "X = standardScaler_X.fit_transform(X)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "respected-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(2),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(150, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['mse'])\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dedicated-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4564 - mse: 0.4564 - val_loss: 0.2643 - val_mse: 0.2643\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3219 - mse: 0.3219 - val_loss: 0.2353 - val_mse: 0.2353\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3156 - mse: 0.3156 - val_loss: 0.2294 - val_mse: 0.2294\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - mse: 0.3109 - val_loss: 0.2456 - val_mse: 0.2456\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - mse: 0.3108 - val_loss: 0.2230 - val_mse: 0.2230\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - mse: 0.3082 - val_loss: 0.2228 - val_mse: 0.2228\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - mse: 0.3115 - val_loss: 0.2215 - val_mse: 0.2215\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3056 - mse: 0.3056 - val_loss: 0.2321 - val_mse: 0.2321\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3049 - mse: 0.3049 - val_loss: 0.2209 - val_mse: 0.2209\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3034 - mse: 0.3034 - val_loss: 0.2437 - val_mse: 0.2437\n",
      "CPU times: user 1.17 s, sys: 168 ms, total: 1.33 s\n",
      "Wall time: 1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161ec8b20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, batch_size=30, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abandoned-handbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.4568 - mse: 0.4568 - 23ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'大体同じ位置に散文している'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)\n",
    "pred = model(X_test).numpy()\n",
    "\n",
    "# plot\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlim(-2,7)\n",
    "plt.ylim(-2,7)\n",
    "plt.scatter(pred, y_test)\n",
    "plt.show()\n",
    "display(\"大体同じ位置に散文している\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "inclusive-installation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (60000, 28, 28)\n",
      "X_test:  (10000, 28, 28)\n",
      "y_train:  (60000, 10)\n",
      "y_test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 問題6 MNIST\n",
    "# 問題5\n",
    "# データセットの読み込み\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "# データフレームから条件抽出\n",
    "\n",
    "# 0 1スケールに変更\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# y次元変換\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = y_train[:, np.newaxis]\n",
    "y_test = y_test[:, np.newaxis]\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.transform(y_test).toarray()\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "australian-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(150, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "# 損失関数 (OHEしてない場合使う)\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# OHEしてる場合はこちら\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "# 以下でもよい\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "another-slave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.2622 - accuracy: 0.9237 - val_loss: 0.1376 - val_accuracy: 0.9588\n",
      "Epoch 2/10\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1129 - accuracy: 0.9652 - val_loss: 0.1235 - val_accuracy: 0.9603\n",
      "Epoch 3/10\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.0777 - accuracy: 0.9760 - val_loss: 0.0958 - val_accuracy: 0.9719\n",
      "Epoch 4/10\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.0604 - accuracy: 0.9801 - val_loss: 0.0900 - val_accuracy: 0.9728\n",
      "Epoch 5/10\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.0454 - accuracy: 0.9846 - val_loss: 0.1006 - val_accuracy: 0.9690\n",
      "Epoch 6/10\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.0387 - accuracy: 0.9871 - val_loss: 0.0896 - val_accuracy: 0.9758\n",
      "Epoch 7/10\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.0314 - accuracy: 0.9895 - val_loss: 0.0964 - val_accuracy: 0.9747\n",
      "Epoch 8/10\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.0278 - accuracy: 0.9903 - val_loss: 0.1016 - val_accuracy: 0.9734\n",
      "Epoch 9/10\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.0222 - accuracy: 0.9924 - val_loss: 0.1005 - val_accuracy: 0.9753\n",
      "Epoch 10/10\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.0994 - val_accuracy: 0.9771\n",
      "CPU times: user 43.1 s, sys: 8.96 s, total: 52.1 s\n",
      "Wall time: 25.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16216e640>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, batch_size=30, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "electrical-salvation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.1037 - accuracy: 0.9757 - 324ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10374914854764938, 0.9757000207901001]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rocky-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題7 pytorch iris2分割\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adaptive-playlist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (80, 4)\n",
      "y_train:  (80,)\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "df = pd.read_csv(\"data/Iris.csv\")\n",
    "\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "\n",
    "# NumPy 配列に変換\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# ラベルを数値に変換\n",
    "y[y == \"Iris-versicolor\"] = 0\n",
    "y[y == \"Iris-virginica\"] = 1\n",
    "# y[y == \"Iris-setosa\"] = 2\n",
    "y = y.astype(np.int64)\n",
    "\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# torchでtensorに変換してdataset作成\n",
    "# train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
    "# test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test))\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fe75182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 1\n",
    "batch_size = 10\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "601cc57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([10, 4]) -- tensor([5.0000, 2.3000, 3.3000, 1.0000])\n",
      "Shape of y: torch.Size([10]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\", \"--\", X[0])\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f93143be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(4, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "#         return nn.functional.log_softmax(logits, dim = 1)\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa622fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "#         X, y = Variable(X), Variable(y)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "#         print(\"pred: \", pred)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbce1fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 0.680894  [    0/   80]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.658904 \n",
      "\n",
      "Epoch 2\n",
      "loss: 0.653356  [    0/   80]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.638312 \n",
      "\n",
      "Epoch 3\n",
      "loss: 0.629608  [    0/   80]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.619749 \n",
      "\n",
      "Epoch 4\n",
      "loss: 0.608441  [    0/   80]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.601311 \n",
      "\n",
      "Epoch 5\n",
      "loss: 0.587216  [    0/   80]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.582632 \n",
      "\n",
      "Epoch 6\n",
      "loss: 0.565632  [    0/   80]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.563293 \n",
      "\n",
      "Epoch 7\n",
      "loss: 0.543148  [    0/   80]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.541993 \n",
      "\n",
      "Epoch 8\n",
      "loss: 0.519266  [    0/   80]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.521837 \n",
      "\n",
      "Epoch 9\n",
      "loss: 0.496296  [    0/   80]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.501243 \n",
      "\n",
      "Epoch 10\n",
      "loss: 0.472824  [    0/   80]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.480378 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(\"Epoch {}\".format(t + 1))\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce594c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (120, 4)\n",
      "y_train:  (120,)\n"
     ]
    }
   ],
   "source": [
    "# 問題7 pytorch iris3分割\n",
    "\n",
    "# データセットの読み込み\n",
    "df = pd.read_csv(\"data/Iris.csv\")\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "\n",
    "# NumPy 配列に変換\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# ラベルを数値に変換\n",
    "y[y == \"Iris-versicolor\"] = 0\n",
    "y[y == \"Iris-virginica\"] = 1\n",
    "y[y == \"Iris-setosa\"] = 2\n",
    "y = y.astype(np.int64)\n",
    "\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# torchでtensorに変換してdataset作成\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# batch_size = 1\n",
    "batch_size = 10\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ec30415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(4, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "#         return nn.functional.log_softmax(logits, dim = 1)\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf10e9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 1.203792  [    0/  120]\n",
      "loss: 0.976244  [  100/  120]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.916719 \n",
      "\n",
      "Epoch 2\n",
      "loss: 0.938624  [    0/  120]\n",
      "loss: 0.862796  [  100/  120]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.786017 \n",
      "\n",
      "Epoch 3\n",
      "loss: 0.840360  [    0/  120]\n",
      "loss: 0.755089  [  100/  120]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.666957 \n",
      "\n",
      "Epoch 4\n",
      "loss: 0.748185  [    0/  120]\n",
      "loss: 0.665221  [  100/  120]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.571876 \n",
      "\n",
      "Epoch 5\n",
      "loss: 0.672283  [    0/  120]\n",
      "loss: 0.598751  [  100/  120]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.501543 \n",
      "\n",
      "Epoch 6\n",
      "loss: 0.616125  [    0/  120]\n",
      "loss: 0.550471  [  100/  120]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.449775 \n",
      "\n",
      "Epoch 7\n",
      "loss: 0.574765  [    0/  120]\n",
      "loss: 0.512561  [  100/  120]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.409420 \n",
      "\n",
      "Epoch 8\n",
      "loss: 0.543256  [    0/  120]\n",
      "loss: 0.481514  [  100/  120]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.376055 \n",
      "\n",
      "Epoch 9\n",
      "loss: 0.517417  [    0/  120]\n",
      "loss: 0.455090  [  100/  120]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.347495 \n",
      "\n",
      "Epoch 10\n",
      "loss: 0.495219  [    0/  120]\n",
      "loss: 0.431695  [  100/  120]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.322459 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(\"Epoch {}\".format(t + 1))\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a3b91f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題8 pytorch housing price\n",
    "\n",
    "# 問題4\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# データセットの読み込み\n",
    "df = pd.read_csv(\"data/housing/train.csv\")\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "\n",
    "# NumPy 配列に変換\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "y = y[:, np.newaxis]\n",
    "\n",
    "# 標準化\n",
    "standardScaler_y = StandardScaler()\n",
    "standardScaler_X = StandardScaler()\n",
    "y = standardScaler_y.fit_transform(y)\n",
    "X = standardScaler_X.fit_transform(X)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# batch_size = 1\n",
    "batch_size = 100\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe9711fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            print(f\"loss: {loss:>7f}\")\n",
    "            loss = loss.item()\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "948557b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 0.972410\n",
      "loss: 0.442261\n",
      "Test Error: \n",
      " Avg loss: 0.631962 \n",
      "\n",
      "Epoch 2\n",
      "loss: 0.450852\n",
      "loss: 0.268567\n",
      "Test Error: \n",
      " Avg loss: 0.463429 \n",
      "\n",
      "Epoch 3\n",
      "loss: 0.288351\n",
      "loss: 0.234846\n",
      "Test Error: \n",
      " Avg loss: 0.440371 \n",
      "\n",
      "Epoch 4\n",
      "loss: 0.257448\n",
      "loss: 0.228221\n",
      "Test Error: \n",
      " Avg loss: 0.440865 \n",
      "\n",
      "Epoch 5\n",
      "loss: 0.252436\n",
      "loss: 0.224075\n",
      "Test Error: \n",
      " Avg loss: 0.442458 \n",
      "\n",
      "Epoch 6\n",
      "loss: 0.250909\n",
      "loss: 0.220700\n",
      "Test Error: \n",
      " Avg loss: 0.444104 \n",
      "\n",
      "Epoch 7\n",
      "loss: 0.250314\n",
      "loss: 0.217597\n",
      "Test Error: \n",
      " Avg loss: 0.445338 \n",
      "\n",
      "Epoch 8\n",
      "loss: 0.249909\n",
      "loss: 0.215070\n",
      "Test Error: \n",
      " Avg loss: 0.446435 \n",
      "\n",
      "Epoch 9\n",
      "loss: 0.249556\n",
      "loss: 0.212739\n",
      "Test Error: \n",
      " Avg loss: 0.447379 \n",
      "\n",
      "Epoch 10\n",
      "loss: 0.249250\n",
      "loss: 0.211022\n",
      "Test Error: \n",
      " Avg loss: 0.448460 \n",
      "\n",
      "CPU times: user 578 ms, sys: 16.8 ms, total: 594 ms\n",
      "Wall time: 154 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(\"Epoch {}\".format(t + 1))\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62ee55a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'大体同じ位置に散文している'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.forward(X_test)\n",
    "\n",
    "# tensor to numpy\n",
    "pred = pred.to('cpu').detach().numpy().copy()\n",
    "# plot\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlim(-2,7)\n",
    "plt.ylim(-2,7)\n",
    "plt.scatter(pred, y_test)\n",
    "plt.show()\n",
    "display(\"大体同じ位置に散文している\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1145215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (60000, 28, 28)\n",
      "X_test:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 問題7 pytorch mnist\n",
    "# データセットの読み込み\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "# データフレームから条件抽出\n",
    "\n",
    "# 0 1スケールに変更\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# batch_size = 1\n",
    "batch_size = 100\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e5f4539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "#         return nn.functional.log_softmax(logits, dim = 1)\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2dfbf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.816263 \n",
      "\n",
      "Epoch 2\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.416382 \n",
      "\n",
      "Epoch 3\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.346746 \n",
      "\n",
      "Epoch 4\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.313544 \n",
      "\n",
      "Epoch 5\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.291012 \n",
      "\n",
      "Epoch 6\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.273239 \n",
      "\n",
      "Epoch 7\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.258332 \n",
      "\n",
      "Epoch 8\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.245331 \n",
      "\n",
      "Epoch 9\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.233490 \n",
      "\n",
      "Epoch 10\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.222993 \n",
      "\n",
      "CPU times: user 22.5 s, sys: 182 ms, total: 22.7 s\n",
      "Wall time: 5.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(\"Epoch {}\".format(t + 1))\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c1719",
   "metadata": {},
   "source": [
    "#### 問題8\n",
    "\n",
    "1. 計算速度 (mnistの学習で比較、epochsは10)\n",
    "\n",
    "tensorFlow: 54s\n",
    "keras: 23.7s\n",
    "pytorch: 5.65s\n",
    "\n",
    "ただしまとめ記事ではkerasが最も遅いらしい。tensorFlowの実相が悪そう\n",
    "    \n",
    "pytorchが早い\n",
    "\n",
    "2. コードの行数・可読性\n",
    "\n",
    "tensorFlow: ニューラルネット層の定義は定義はしやすい。重み、バイアスの定義が必要。batchは自前実装。他二つで比べると最も行数が多い。numpyのまま入力できるのがわかやすい。\n",
    "keras: 最もコード量が少ない。読みやすい。\n",
    "pytorch: 上二つの間ぐらい。\n",
    "    \n",
    "keras. pytorchは独自の型にnumpyのデータをエンコード、デコードするのが厄介。またエンコード後のデータもイテレーターだからか確認しにくい。\n",
    "\n",
    "3. 用意されている機能\n",
    "\n",
    "tensorFlow: ニューラルネット層の定義、それぞれ損失値を出す関数が良いされてるが、学習ロジックは自分で組み立てる必要あり\n",
    "keras: ニューラルネット層の定義, バッチ処理、epoch回数指定, 学習ロジック、損失値計算、データセット\n",
    "pytorch: ニューラルネット層の定義, バッチ処理, それぞれ損失値を出す関数が良いされてるが、学習ロジックは自分で組み立てる必要あり\n",
    "\n",
    "\n",
    "kerasが一番サクッと組めるが、細かい部分までカスタマイズしたい場合、pytorchが有効そう。\n",
    "また、、学習経過などをさらに細かく独自にdebugしたい場合はkerasだとかなりラップされてるのでpytorchの方が良さそう。\n",
    "GPU切り替えもpytorchの方が簡単らしい。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
