{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "living-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from IPython.display import Image\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unnecessary-violation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n",
      "(48000, 784)\n",
      "(12000, 784)\n",
      "(48000,)\n",
      "(12000,)\n",
      "(48000, 10)\n",
      "(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "# MNISTデータをmodel入力用に整形\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])\n",
    "# 1次元にする\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 一つ可視化\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "\n",
    "# scaleを0 ~ 255から0 ~ 1にする\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0\n",
    "\n",
    "# OHE作成\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n",
    "\n",
    "# トレーニングとテストデータに分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)\n",
    "print(y_train.shape) # (12000, 784)\n",
    "print(y_val.shape) # (12000, 784)\n",
    "\n",
    "# 分割後のyにOHE適用\n",
    "y_train = enc.transform(y_train[:, np.newaxis])\n",
    "y_val = enc.transform(y_val[:, np.newaxis])\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protected-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチ\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "peaceful-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果確認、分析用の関数\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# scoreまとめ表示\n",
    "def eval_accuracy(model, X_test, y_test, model_name):\n",
    "    pred_y = model.predict(X_test)\n",
    "    nn_result = pd.DataFrame(\n",
    "        [accuracy_score(y_test, pred_y), precision_score(y_test, pred_y, average='micro'), recall_score(y_test, pred_y, average='micro')],\n",
    "        index=['Accuracy', 'Precision', 'Recall'],\n",
    "        columns=[model_name]\n",
    "    )\n",
    "    return nn_result\n",
    "\n",
    "# 損失値の推移\n",
    "def display_loss_graph(model):\n",
    "    iter_list = list(range(len(model.loss_train)))\n",
    "    plt.scatter(iter_list, model.loss_train, label=\"train loss\")\n",
    "    plt.scatter(iter_list, model.loss_val, label=\"test loss\")\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('iter')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "double-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題1\n",
    "class SimpleConv1d:\n",
    "    def forward(self, X, W, b):\n",
    "        self.X = X\n",
    "        self.W = W\n",
    "        X_len = len(X)\n",
    "        W_len = len(W)\n",
    "        self.A = np.empty(X_len - W_len +1)\n",
    "        indexes = np.empty((X_len - W_len +1, W_len))\n",
    "\n",
    "        for i in range(X_len):\n",
    "            if len(X[i :]) < W_len:\n",
    "                break\n",
    "            indexes[i] = list(range(i, i + W_len, 1))\n",
    "\n",
    "        self.A = np.sum(X[indexes.astype(np.int)] * W, axis=1) + b[0]\n",
    "        return self.A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dX_len = len(self.X)\n",
    "        dA_len = len(dA)\n",
    "        W_len = len(self.W)\n",
    "        indexes = np.empty((W_len, dA_len))\n",
    "        for s in range(W_len):\n",
    "            indexes[s] = list(range(s, s + dA_len, 1))\n",
    "\n",
    "        dW = np.sum(dA * self.X[indexes.astype(np.int)], axis=1)\n",
    "        dB = np.sum(dA)\n",
    "\n",
    "        tmp_dA = np.tile(dA, (W_len,1))\n",
    "        tmp_dA = np.pad(tmp_dA, [(0,0), (0, dX_len - dA_len)], \"constant\")\n",
    "        for s in range(W_len):\n",
    "            tmp_dA[s] = np.roll(tmp_dA[s], s)\n",
    "        dX = self.W @ tmp_dA\n",
    "\n",
    "        return dW, dB, dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vulnerable-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_n_out(n_in, n_padding, n_f, n_stride):\n",
    "    n_out = ((n_in + (2 * n_padding) - n_f ) / n_stride) + 1\n",
    "    return int(n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "entitled-latex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_n_out(784, 0, 7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "varying-council",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 50,  80, 110]), 30, array([ 30, 110, 170, 140]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 問題3\n",
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "sconv1 = SimpleConv1d()\n",
    "sconv1.forward(x, w, b)\n",
    "delta_a = np.array([10, 20])\n",
    "sconv1.backward(delta_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continent-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bottom-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題4\n",
    "class Conv1dP4:\n",
    "    def forward(self, X, W, b):\n",
    "        self.n_in_channel = X.shape[0]\n",
    "        self.n_features = X.shape[-1]\n",
    "        self.W = W\n",
    "        self.n_out_channel = W.shape[0]\n",
    "        self.filter_size = W.shape[-1]\n",
    "        \n",
    "        # 各チャネルのXの右にfilter_size-1分の0を右埋め\n",
    "        self.X = np.pad(x, ((0,0), ((self.filter_size-1), 0)))\n",
    "        \n",
    "        # A産出量のXを変形させた配列\n",
    "        self.X1 = np.zeros((self.n_in_channel, self.filter_size,  self.filter_size - 1 +  self.n_features))\n",
    "        \n",
    "        # のちにチャネルごとにwをかけた値をチャンネル横断で和を計算するために左を0埋めしたself.Xを一段ずつ左シフトさせていく\n",
    "        for i in range(self.filter_size):\n",
    "            self.X1[:, i] = np.roll(self.X, -i, axis=-1)\n",
    "\n",
    "        temp_X1 = self.X1[:, :,  self.filter_size - 1:self.n_features]\n",
    "        temp_W = self.W[:, :, :, np.newaxis]\n",
    "        A = np.sum(temp_X1* temp_W, axis=(1,2)) + b.reshape(len(b),1)\n",
    "\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        n_a_features = dA.shape[-1]\n",
    "        # dW\n",
    "        temp_dA = dA[:, np.newaxis, np.newaxis]\n",
    "        temp_X1 = self.X1[np.newaxis, :, :,  self.filter_size - 1:self.n_features]\n",
    "        dW = np.sum(temp_dA *temp_X1, axis=(-1))\n",
    "        # dB\n",
    "        dB = np.sum(dA, axis=1)\n",
    "        \n",
    "        # dX\n",
    "        self.dA = np.zeros((self.n_out_channel, self.filter_size, self.n_features))\n",
    "        padded_dA = np.pad(dA, [(0, 0), (0, self.n_features - n_a_features)], \"constant\")\n",
    "        \n",
    "        for i in range(self.filter_size):\n",
    "            self.dA[:, i] = np.roll(padded_dA, i, axis=-1)\n",
    "        \n",
    "        temp_W = self.W[:, :, :, np.newaxis]\n",
    "        temp_dA = self.dA[:, np.newaxis]\n",
    "        \n",
    "        dX = np.sum(temp_W * temp_dA, axis=(0, 2))\n",
    "        return dW, dB, dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "absent-constant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  [[16. 22.]\n",
      " [17. 23.]\n",
      " [18. 24.]]\n",
      "dW:  [[[ 60.  98. 136.]\n",
      "  [ 98. 136. 174.]]\n",
      "\n",
      " [[ 63. 103. 143.]\n",
      "  [103. 143. 183.]]\n",
      "\n",
      " [[ 66. 108. 150.]\n",
      "  [108. 150. 192.]]]\n",
      "dB:  [38. 40. 42.]\n",
      "dX:  [[ 51. 120. 120.  69.]\n",
      " [ 51. 120. 120.  69.]]\n"
     ]
    }
   ],
   "source": [
    "conv1d = Conv1dP4()\n",
    "A = conv1d.forward(x, w, b)\n",
    "print(\"A: \", A)\n",
    "dW, dB, dX = conv1d.backward(A)\n",
    "print(\"dW: \", dW)\n",
    "print(\"dB: \", dB)\n",
    "print(\"dX: \", dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "friendly-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題5\n",
    "class Conv1dP5:\n",
    "    \n",
    "    def __init__(self, n_padding=0):\n",
    "        self.n_padding = n_padding\n",
    "\n",
    "    def forward(self, X, W, b):\n",
    "        self.n_in_channel = X.shape[0]\n",
    "        self.n_features = X.shape[-1]\n",
    "        self.W = W\n",
    "        self.n_out_channel = W.shape[0]\n",
    "        self.filter_size = W.shape[-1]\n",
    "        self.n_out = calc_n_out(self.n_features, self.n_padding, self.filter_size, 1)\n",
    "        \n",
    "        # 各チャネルのXの右にfilter_size-1分の0を右埋め\n",
    "        self.X = np.pad(x, ((0,0), ((self.filter_size-1), 0)))\n",
    "        \n",
    "        # A産出量のXを変形させた配列\n",
    "        self.X1 = np.zeros((self.n_in_channel, self.filter_size,  self.filter_size - 1 +  self.n_features))\n",
    "        \n",
    "        # のちにチャネルごとにwをかけた値をチャンネル横断で和を計算するために左を0埋めしたself.Xを一段ずつ左シフトさせていく\n",
    "        for i in range(self.filter_size):\n",
    "            self.X1[:, i] = np.roll(self.X, -i, axis=-1)\n",
    "\n",
    "        temp_X1 = self.X1[:, :,  self.filter_size - 1 - self.n_padding:self.n_features + self.n_padding]\n",
    "        temp_W = self.W[:, :, :, np.newaxis]\n",
    "        A = np.sum(temp_X1* temp_W, axis=(1,2)) + b.reshape(len(b),1)\n",
    "\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        n_a_features = dA.shape[-1]\n",
    "        # dW\n",
    "        temp_dA = dA[:, np.newaxis, np.newaxis]\n",
    "        temp_X1 = self.X1[np.newaxis, :, :,  self.filter_size - 1 - self.n_padding:self.n_features + self.n_padding]\n",
    "        dW = np.sum(temp_dA *temp_X1, axis=(-1))\n",
    "\n",
    "        # dB\n",
    "        dB = np.sum(dA, axis=1)\n",
    "        \n",
    "        # dX\n",
    "        self.dA = np.zeros((self.n_out_channel, self.filter_size, self.n_features))\n",
    "        padded_dA = np.pad(dA, [(0, 0), (0, self.n_features - n_a_features)], \"constant\")\n",
    "        \n",
    "        for i in range(self.filter_size):\n",
    "            self.dA[:, i] = np.roll(padded_dA, i, axis=-1)\n",
    "        \n",
    "        temp_W = self.W[:, :, :, np.newaxis]\n",
    "        temp_dA = self.dA[:, np.newaxis]\n",
    "        \n",
    "        dX = np.sum(temp_W * temp_dA, axis=(0, 2))\n",
    "        return dW, dB, dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "amateur-frost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  [[ 9. 16. 22. 17.]\n",
      " [10. 17. 23. 18.]\n",
      " [11. 18. 24. 19.]]\n",
      "dW:  [[[111. 175. 154.]\n",
      "  [166. 239. 201.]]\n",
      "\n",
      " [[117. 185. 163.]\n",
      "  [175. 253. 213.]]\n",
      "\n",
      " [[123. 195. 172.]\n",
      "  [184. 267. 225.]]]\n",
      "dB:  [64. 68. 72.]\n",
      "dX:  [[153. 135. 150. 174.]\n",
      " [153. 135. 150. 174.]]\n"
     ]
    }
   ],
   "source": [
    "conv1d = Conv1dP5(n_padding=1)\n",
    "A = conv1d.forward(x, w, b)\n",
    "print(\"A: \", A)\n",
    "dW, dB, dX = conv1d.backward(A)\n",
    "print(\"dW: \", dW)\n",
    "print(\"dB: \", dB)\n",
    "print(\"dX: \", dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "revolutionary-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題6\n",
    "class Conv1dP6:\n",
    "    def __init__(self, n_padding=0):\n",
    "        self.n_padding = n_padding\n",
    "\n",
    "    def forward(self, X, W, b):\n",
    "        self.n_records = X.shape[0]\n",
    "        self.n_in_channel = X.shape[1]\n",
    "        self.n_features = X.shape[-1]\n",
    "        self.W = W\n",
    "        self.n_out_channel = W.shape[0]\n",
    "        self.filter_size = W.shape[-1]\n",
    "        self.n_out = calc_n_out(self.n_features, self.n_padding, self.filter_size, 1)\n",
    "        \n",
    "        # 各チャネルのXの右にfilter_size-1分の0を右埋め\n",
    "        self.X = np.pad(X, ((0,0), (0,0), ((self.filter_size-1), 0)))\n",
    "        \n",
    "        # A産出量のXを変形させた配列\n",
    "        self.X1 = np.zeros((self.n_records, self.n_in_channel, self.filter_size,  self.filter_size - 1 +  self.n_features))\n",
    "        \n",
    "        # のちにチャネルごとにwをかけた値をチャンネル横断で和を計算するために左を0埋めしたself.Xを一段ずつ左シフトさせていく\n",
    "        for i in range(self.filter_size):\n",
    "            self.X1[:, :, i] = np.roll(self.X, -i, axis=-1)\n",
    "\n",
    "        temp_X1 = self.X1[:, np.newaxis,  :, :, self.filter_size - 1 - self.n_padding:self.n_features + self.n_padding]\n",
    "        temp_W = self.W[:, :, :, np.newaxis]\n",
    "\n",
    "        A = np.sum(temp_X1* temp_W, axis=(2,3)) + b.reshape(len(b),1)\n",
    "\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        n_a_features = dA.shape[-1]\n",
    "        # dW\n",
    "        temp_dA = dA[:, :, np.newaxis, np.newaxis]\n",
    "        temp_X1 = self.X1[:, np.newaxis, :, :,  self.filter_size - 1 - self.n_padding:self.n_features + self.n_padding]\n",
    "\n",
    "        dW = np.sum(temp_dA *temp_X1, axis=(0, -1))\n",
    "\n",
    "        # dB\n",
    "        dB = np.sum(dA, axis=(0, -1))\n",
    "        \n",
    "        # dX\n",
    "        self.dA = np.zeros((self.n_records, self.n_out_channel, self.filter_size, self.n_features))\n",
    "        padded_dA = np.pad(dA, [(0, 0), (0, 0), (0, self.n_features - n_a_features)], \"constant\")\n",
    "        \n",
    "        for i in range(self.filter_size):\n",
    "            self.dA[:, :, i] = np.roll(padded_dA, i, axis=-1)\n",
    "        \n",
    "        temp_W = self.W[:, :, :, np.newaxis]\n",
    "        temp_dA = self.dA[:, :, np.newaxis]\n",
    "        \n",
    "        dX = np.sum(temp_W * temp_dA, axis=(1, 3))\n",
    "        return dW, dB, dX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "white-content",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  [[[16. 22.]\n",
      "  [17. 23.]\n",
      "  [18. 24.]]\n",
      "\n",
      " [[55. 61.]\n",
      "  [56. 62.]\n",
      "  [57. 63.]]]\n",
      "dW:  [[[ 817.  971. 1125.]\n",
      "  [1319. 1473. 1627.]]\n",
      "\n",
      " [[ 833.  991. 1149.]\n",
      "  [1345. 1503. 1661.]]\n",
      "\n",
      " [[ 849. 1011. 1173.]\n",
      "  [1371. 1533. 1695.]]]\n",
      "dB:  [154. 158. 162.]\n",
      "dX:  [[[ 51. 120. 120.  69.]\n",
      "  [ 51. 120. 120.  69.]]\n",
      "\n",
      " [[168. 354. 354. 186.]\n",
      "  [168. 354. 354. 186.]]]\n"
     ]
    }
   ],
   "source": [
    "x2 = np.array([[[1, 2, 3, 4], [2, 3, 4, 5]], [[6, 7, 8, 9], [10, 11, 12, 13]]]) # shape(2, 2, 4)で、（入力データ数, 入力チャンネル数、特徴量数）である。\n",
    "conv1d = Conv1dP6(n_padding=0)\n",
    "A = conv1d.forward(x2, w, b)\n",
    "print(\"A: \", A)\n",
    "dW, dB, dX = conv1d.backward(A)\n",
    "print(\"dW: \", dW)\n",
    "print(\"dB: \", dB)\n",
    "print(\"dX: \", dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "metric-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題7\n",
    "class Conv1dP7:\n",
    "    def __init__(self, n_padding=0, n_stride=1):\n",
    "        self.n_padding = n_padding\n",
    "        self.n_stride = n_stride\n",
    "\n",
    "    def forward(self, X, W, b):\n",
    "        self.n_records = X.shape[0]\n",
    "        self.n_in_channel = X.shape[1]\n",
    "        self.n_features = X.shape[-1]\n",
    "        self.W = W\n",
    "        self.n_out_channel = W.shape[0]\n",
    "        self.filter_size = W.shape[-1]\n",
    "        self.n_out = calc_n_out(self.n_features, self.n_padding, self.filter_size, self.n_stride)\n",
    "        \n",
    "        # 各チャネルのXの右にfilter_size-1分の0を右埋め\n",
    "        self.X = np.pad(X, ((0,0), (0,0), ((self.filter_size-1), 0)))\n",
    "        \n",
    "        # A産出量のXを変形させた配列\n",
    "        self.X1 = np.zeros((self.n_records, self.n_in_channel, self.filter_size,  self.filter_size - 1 +  self.n_features))\n",
    "        \n",
    "        # のちにチャネルごとにwをかけた値をチャンネル横断で和を計算するために左を0埋めしたself.Xを一段ずつ左シフトさせていく\n",
    "        for i in range(self.filter_size):\n",
    "            self.X1[:, :, i] = np.roll(self.X, -i, axis=-1)\n",
    "\n",
    "        temp_X1 = self.X1[:, np.newaxis,  :, :, self.filter_size - 1 - self.n_padding:self.n_features + self.n_padding:self.n_stride]\n",
    "        temp_W = self.W[:, :, :, np.newaxis]\n",
    "\n",
    "        A = np.sum(temp_X1* temp_W, axis=(2,3)) + b.reshape(len(b),1)\n",
    "\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        n_a_features = dA.shape[-1]\n",
    "        # dW\n",
    "        temp_dA = dA[:, :, np.newaxis, np.newaxis]\n",
    "        temp_X1 = self.X1[:, np.newaxis, :, :,  self.filter_size - 1 - self.n_padding:self.n_features + self.n_padding:self.n_stride]\n",
    "\n",
    "        dW = np.sum(temp_dA *temp_X1, axis=(0, -1))\n",
    "\n",
    "        # dB\n",
    "        dB = np.sum(dA, axis=(0, -1))\n",
    "        \n",
    "        # dX\n",
    "        self.dA = np.zeros((self.n_records, self.n_out_channel, self.filter_size, self.n_features))\n",
    "        padded_dA = np.pad(dA, [(0, 0), (0, 0), (0, self.n_features - n_a_features)], \"constant\")\n",
    "        \n",
    "        for i in range(self.filter_size):\n",
    "            self.dA[:, :, i] = np.roll(padded_dA, i, axis=-1)\n",
    "        \n",
    "        temp_W = self.W[:, :, :, np.newaxis]\n",
    "        temp_dA = self.dA[:, :, np.newaxis]\n",
    "        \n",
    "        dX = np.sum(temp_W * temp_dA, axis=(1, 3))\n",
    "        return dW, dB, dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "coated-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2 = np.array([[[1, 2, 3, 4], [2, 3, 4, 5]], [[6, 7, 8, 9], [10, 11, 12, 13]]]) # shape(2, 2, 4)で、（入力データ数, 入力チャンネル数、特徴量数）である。\n",
    "# w = np.ones((1, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "# b = np.array([1, 2, 3]) # （出力チャンネル数）\n",
    "# conv1d = Conv1dP7(n_padding=0, n_stride=1)\n",
    "# A = conv1d.forward(x2, w, b)\n",
    "# print(\"A: \", A.shape, A)\n",
    "# dW, dB, dX = conv1d.backward(A)\n",
    "# print(\"dW: \", dW.shape, dW)\n",
    "# print(\"dB: \", dB.shape, dB)\n",
    "# print(\"dX: \", dX.shape, dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "romance-memorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  (2, 3, 1) [[[16.]\n",
      "  [17.]\n",
      "  [18.]]\n",
      "\n",
      " [[55.]\n",
      "  [56.]\n",
      "  [57.]]]\n",
      "dW:  (3, 2, 3) [[[346. 417. 488.]\n",
      "  [582. 653. 724.]]\n",
      "\n",
      " [[353. 426. 499.]\n",
      "  [594. 667. 740.]]\n",
      "\n",
      " [[360. 435. 510.]\n",
      "  [606. 681. 756.]]]\n",
      "dB:  (3,) [71. 73. 75.]\n",
      "dX:  (2, 2, 4) [[[ 51.  51.  51.   0.]\n",
      "  [ 51.  51.  51.   0.]]\n",
      "\n",
      " [[168. 168. 168.   0.]\n",
      "  [168. 168. 168.   0.]]]\n"
     ]
    }
   ],
   "source": [
    "x2 = np.array([[[1, 2, 3, 4], [2, 3, 4, 5]], [[6, 7, 8, 9], [10, 11, 12, 13]]]) # shape(2, 2, 4)で、（入力データ数, 入力チャンネル数、特徴量数）である。\n",
    "conv1d = Conv1dP7(n_padding=0, n_stride=2)\n",
    "A = conv1d.forward(x2, w, b)\n",
    "print(\"A: \", A.shape, A)\n",
    "dW, dB, dX = conv1d.backward(A)\n",
    "print(\"dW: \", dW.shape, dW)\n",
    "print(\"dB: \", dB.shape, dB)\n",
    "print(\"dX: \", dX.shape, dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "postal-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNNの時に作成したclass, method\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        \n",
    "        # AdaGrad\n",
    "        self.HW = None\n",
    "        self.HB = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.Z = X\n",
    "#         print(\" FC foward W: \", self.W.shape)\n",
    "#         print(\" FC foward B: \", self.B.shape)\n",
    "#         print(\" FC foward X: \", X.shape)\n",
    "        return X @ self.W + self.B\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dA = dA\n",
    "        self.dZ = dA @ self.W.T\n",
    "        # 更新\n",
    "        self.optimizer.update(self)\n",
    "        return self.dZ\n",
    "\n",
    "class SimpleInitializer:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, *shape):\n",
    "        W = self.sigma * np.random.randn(*shape)\n",
    "        return W\n",
    "    def B(self, *shape):\n",
    "        B = self.sigma * np.random.randn(*shape)\n",
    "        return B\n",
    "    \n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr, ada_grad):\n",
    "        self.lr = lr\n",
    "        self.ada_grad = ada_grad\n",
    "\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "\n",
    "        dW = layer.Z.T @ layer.dA\n",
    "        dB = np.sum(layer.dA, axis=0)\n",
    "\n",
    "        # AdaGrad\n",
    "        if self.ada_grad == True:\n",
    "            # AdaGrad W\n",
    "            dW_squared = dW * dW\n",
    "            if layer.HW is None:\n",
    "                layer.HW = dW_squared\n",
    "            else:\n",
    "                layer.HW += dW_squared\n",
    "            dW = dW / (np.sqrt(layer.HW) + 1e-7)\n",
    "\n",
    "            # AdaGrad B\n",
    "            dB_squared = dB * dB\n",
    "            if layer.HB is None:\n",
    "                layer.HB = dB_squared\n",
    "            else:\n",
    "                layer.HB += dB_squared\n",
    "                \n",
    "            dB = dB / (np.sqrt( layer.HB)  + 1e-7)\n",
    "\n",
    "        layer.W -= self.lr * dW\n",
    "        layer.B -= self.lr * dB\n",
    "        \n",
    "import copy\n",
    "class SGDForCLayer:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr, ada_grad):\n",
    "        self.lr = lr\n",
    "        self.ada_grad = ada_grad\n",
    "\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        dW_copied = copy.deepcopy(layer.dW)\n",
    "        dB_copied = copy.deepcopy(layer.dB)\n",
    "\n",
    "        # AdaGrad\n",
    "        if self.ada_grad == True:\n",
    "            # AdaGrad W\n",
    "            dW_squared = layer.dW * layer.dW\n",
    "            if layer.HW is None:\n",
    "                layer.HW = dW_squared\n",
    "            else:\n",
    "                layer.HW += dW_squared\n",
    "            dB_copied = layer.dW / (np.sqrt(layer.HW) + 1e-7)\n",
    "\n",
    "            # AdaGrad B\n",
    "            dB_squared = layer.dB * layer.dB\n",
    "            if layer.HB is None:\n",
    "                layer.HB = dB_squared\n",
    "            else:\n",
    "                layer.HB += dB_squared\n",
    "                \n",
    "            dB_copied = layer.dB / (np.sqrt( layer.HB)  + 1e-7)\n",
    "\n",
    "        layer.W -= self.lr * dW_copied\n",
    "        layer.B -= self.lr * dB_copied\n",
    "\n",
    "class Tanh():\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return (np.exp(A) - np.exp(-A)) / (np.exp(A) + np.exp(-A))\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        return dZ * (1.0 - (self.forward(self.A) ** 2))\n",
    "        \n",
    "class Sigmoid():\n",
    "\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return 1.0 / (1.0 + np.exp(-A))\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "         return dZ * (self.forward(self.A) * (1.0 - self.forward(self.A)))\n",
    "\n",
    "class ReLU():\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.max([np.zeros(A.shape), A], axis=0)\n",
    "\n",
    "    def backward(self, dZ):\n",
    "        return dZ * np.where(self.A < 0, 1, 0)\n",
    "\n",
    "class Softmax():\n",
    "    def forward(self, X):\n",
    "         return np.exp(X) / np.sum(np.exp(X), axis=1, keepdims=True)\n",
    "        \n",
    "    def backward(self, Z, Y):\n",
    "        dA =  (Z - Y) / len(Y)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acute-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題8\n",
    "class Conv1d:\n",
    "    def __init__(self, initializer, optimizer, filter_size = 1, n_in_channel = 1, n_out_channel = 1, n_padding=0, n_stride=1):\n",
    "        self.n_padding = n_padding\n",
    "        self.n_stride = n_stride\n",
    "        self.filter_size = filter_size\n",
    "        self.n_in_channel = n_in_channel\n",
    "        self.n_out_channel = n_out_channel\n",
    "        self.W = initializer.W(n_out_channel, n_in_channel, filter_size)\n",
    "        self.B = initializer.B(n_out_channel)\n",
    "        \n",
    "        self.n_out_features = None\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # AdaGrad\n",
    "        self.HW = None\n",
    "        self.HB = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.n_records = X.shape[0]\n",
    "        n_all_features = X.shape[-1]\n",
    "        self.n_features_in_channel = int(n_all_features / self.n_in_channel)\n",
    "        X = X.reshape(self.n_records, self.n_in_channel, self.n_features_in_channel)\n",
    "        self.Z = X\n",
    "\n",
    "        # 各チャネルのXの右にfilter_size-1分の0を右埋め\n",
    "        self.X = np.pad(X, ((0,0), (0,0), ((self.filter_size-1), 0)))\n",
    "        \n",
    "        # A産出量のXを変形させた配列\n",
    "        self.X1 = np.zeros((self.n_records, self.n_in_channel, self.filter_size,  self.filter_size - 1 +  self.n_features_in_channel))\n",
    "        \n",
    "        # のちにチャネルごとにwをかけた値をチャンネル横断で和を計算するために左を0埋めしたself.Xを一段ずつ左シフトさせていく\n",
    "        for i in range(self.filter_size):\n",
    "            self.X1[:, :, i] = np.roll(self.X, -i, axis=-1)\n",
    "\n",
    "        temp_X1 = self.X1[:, np.newaxis,  :, :, self.filter_size - 1 - self.n_padding:self.n_features_in_channel + self.n_padding:self.n_stride]\n",
    "        temp_W = self.W[:, :, :, np.newaxis]\n",
    "        \n",
    "        A = np.sum(temp_X1* temp_W, axis=(2,3)) + self.B.reshape(len(self.B),1)\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        n_a_features = dA.shape[-1]\n",
    "        # dW\n",
    "        temp_dA = dA[:, :, np.newaxis, np.newaxis]\n",
    "        temp_X1 = self.X1[:, np.newaxis, :, :,  self.filter_size - 1 - self.n_padding:self.n_features_in_channel + self.n_padding:self.n_stride]\n",
    "\n",
    "        self.dW = np.sum(temp_dA *temp_X1, axis=(0, -1))\n",
    "\n",
    "        # dB\n",
    "        self.dB = np.sum(dA, axis=(0, -1))\n",
    "        \n",
    "        # dX\n",
    "        self.dA = np.zeros((self.n_records, self.n_out_channel, self.filter_size, self.n_features_in_channel))\n",
    "        padded_dA = np.pad(dA, [(0, 0), (0, 0), (0, self.n_features_in_channel - n_a_features)], \"constant\")\n",
    "        \n",
    "        for i in range(self.filter_size):\n",
    "            self.dA[:, :, i] = np.roll(padded_dA, i, axis=-1)\n",
    "        \n",
    "        temp_W = self.W[:, :, :, np.newaxis]\n",
    "        temp_dA = self.dA[:, :, np.newaxis]\n",
    "        \n",
    "        self.dX = np.sum(temp_W * temp_dA, axis=(1, 3))\n",
    "        \n",
    "        # 更新\n",
    "        self.optimizer.update(self)\n",
    "        \n",
    "        return self.dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "imposed-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2 = np.array([[[1, 2, 3, 4], [2, 3, 4, 5]], [[6, 7, 8, 9], [10, 11, 12, 13]]]) # shape(2, 2, 4)で、（入力データ数, 入力チャンネル数、特徴量数）である。\n",
    "# # x = np.array([[1, 2, 3, 4, 1, 2, 3, 4], [2, 3, 4, 5, 2, 3, 4, 5], [6, 7, 8, 9, 6, 7, 8, 9], [10, 11, 12, 13, 10, 11, 12, 13]])\n",
    "# x = np.array([[1, 2, 3, 4, 1, 2, 3, 4], [2, 3, 4, 5, 2, 3, 4, 5]])\n",
    "# conv1d = Conv1d(filter_size=3, initializer=SimpleInitializer(0.01), optimizer=SGDForCLayer(0.01, False), n_in_channel=2, n_out_channel=1, n_padding=0, n_stride=1)\n",
    "# A = conv1d.forward(x)\n",
    "# print(\"A: \", A.shape, A)\n",
    "# dW, dB, dX = conv1d.backward(A)\n",
    "# print(\"dW: \", dW.shape, dW)\n",
    "# print(\"dB: \", dB.shape, dB)\n",
    "# print(\"dX: \", dX.shape, dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "veterinary-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchCNNClassifier():\n",
    "    def __init__(self, batch_size = 20, n_cell_layers = [400, 200, 10], sigma = 0.02, lr = 0.01, n_in_channel = 1, n_out_channel = 1, n_padding = 0, n_stride =1, filter_size = 7, epoch = 10, activation_func = \"Tanh\", ada_grad = True, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        # 一度に学習させるデータの数\n",
    "        self.batch_size = batch_size\n",
    "        # 層毎のnode数\n",
    "        self.n_cell_layers = n_cell_layers\n",
    "        # 正規分布の平均値\n",
    "        self.sigma = sigma\n",
    "        # 学習率\n",
    "        self.lr = lr\n",
    "        # 学習回数\n",
    "        self.epoch = epoch\n",
    "        # 活性化関数\n",
    "        self.activation_func = activation_func\n",
    "        # adaGrad\n",
    "        self.ada_grad = ada_grad\n",
    "        \n",
    "        # 畳み込み関連\n",
    "        self.n_in_channel = n_in_channel\n",
    "        self.n_out_channel = n_out_channel\n",
    "        self.n_padding = n_padding\n",
    "        self.n_stride = n_stride\n",
    "        self.filter_size = filter_size\n",
    "        self.conv1d = None\n",
    "\n",
    "        self.activations = []\n",
    "        self.FCs = []\n",
    "\n",
    "        self.loss_train = []\n",
    "        self.loss_val = []\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        # self.sigma : ガウス分布の標準偏差\n",
    "        # self.lr : 学習率\n",
    "        # self.n_nodes1 : 1層目のノード数\n",
    "        # self.n_nodes2 : 2層目のノード数\n",
    "        # self.n_output : 出力層のノード数\n",
    "\n",
    "        # SGD: Stochastic Gradient Descent、確率的勾配降下法\n",
    "        # FC:  結合層\n",
    "        optimizer = SGD(self.lr, self.ada_grad)\n",
    "        n_all_features = X_train.shape[-1]\n",
    "        n_conv1d_out_features = calc_n_out(int(n_all_features / self.n_in_channel), self.n_padding, self.filter_size, self.n_stride)\n",
    "        \n",
    "        # 畳み込み層初期化\n",
    "        self.conv1d = Conv1d(filter_size=self.filter_size, initializer=SimpleInitializer(self.sigma), optimizer=SGDForCLayer(self.lr, self.ada_grad), n_in_channel=self.n_in_channel, n_out_channel=self.n_out_channel, n_padding=self.n_padding, n_stride=self.n_stride)\n",
    "        \n",
    "#         self.conv1d.n_out_features = calc_n_out(n_all_features, self.n_padding, self.filter_size, self.n_stride)\n",
    "        # 結合層初期化\n",
    "        for i, n_cells in enumerate(self.n_cell_layers):\n",
    "            if i == 0:\n",
    "                self.FCs.append(FC(n_conv1d_out_features, self.n_cell_layers[i], SimpleInitializer(self.sigma), optimizer))\n",
    "            else:\n",
    "                self.FCs.append(FC(self.n_cell_layers[i-1], self.n_cell_layers[i], SimpleInitializer(self.sigma), optimizer))\n",
    "\n",
    "            if i != len(self.n_cell_layers) -1:\n",
    "                self.activations.append(self.__activation_func())\n",
    "            else:\n",
    "                self.activations.append(Softmax())\n",
    "\n",
    "        for _ in range(self.epoch):\n",
    "            # 全データを使わず一部のデータを使って重みを算出する\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # 各層のA, Zを計算\n",
    "                Z_out = self.forward(mini_X_train)\n",
    "                # 各W, Bを更新\n",
    "                self.backward(Z_out, mini_y_train)\n",
    "            # 学習後、全データでA,Z計算\n",
    "            pred_y = self.forward(X)\n",
    "            # 損失計算\n",
    "            self.loss_train.append(self.cross_entropy_error(y, pred_y))\n",
    "            if X_val is not None:\n",
    "                pred_y_val = self.forward(X_val)\n",
    "                self.loss_val.append(self.cross_entropy_error(y_val, pred_y_val))\n",
    "        if self.verbose:\n",
    "            if X_val is None:\n",
    "                print(self.loss_train)\n",
    "            else:\n",
    "                print(self.loss_train,self.loss_val)\n",
    "\n",
    "    # フォワードプロパゲーション\n",
    "    def forward(self, X):\n",
    "        Z = X\n",
    "        # 畳み込み層\n",
    "        Z = self.conv1d.forward(Z)\n",
    "        Z = Z.reshape(Z.shape[0], Z.shape[-1])\n",
    "        # 結合層\n",
    "        for i, n_cells in enumerate(self.n_cell_layers):\n",
    "            A = self.FCs[i].forward(Z)\n",
    "            Z = self.activations[i].forward(A)\n",
    "\n",
    "        return Z\n",
    "    \n",
    "    # バックプロパゲーション\n",
    "    def backward(self, Z, Y):\n",
    "        # 結合層\n",
    "        dZ = None\n",
    "        for i, n_cells in enumerate(self.n_cell_layers):                \n",
    "            inverse_i = len(self.n_cell_layers) - (i + 1)\n",
    "\n",
    "            dA = None\n",
    "            if i == 0:\n",
    "                dA = self.activations[inverse_i].backward(Z, Y)\n",
    "            else:\n",
    "                dA = self.activations[inverse_i].backward(dZ)\n",
    "\n",
    "            dZ = self.FCs[inverse_i].backward(dA)\n",
    "\n",
    "        # 畳み込み層\n",
    "        \n",
    "        dZ = dZ[:, np.newaxis, :]\n",
    "        dZ = self.conv1d.backward(dZ)\n",
    "        \n",
    "        return dZ\n",
    "\n",
    "    def __activation_func(self):\n",
    "        if self.activation_func == \"Tanh\":\n",
    "            return Tanh()\n",
    "        elif self.activation_func == \"ReLU\":\n",
    "            return ReLU()\n",
    "\n",
    "    # 損失関数\n",
    "    def cross_entropy_error(self, y, Z):\n",
    "        L = - np.sum(y * np.log(Z+1e-7)) / len(y)\n",
    "        return L\n",
    "        \n",
    "    def predict(self, X):\n",
    "        pred = self.forward(X)\n",
    "        return np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "happy-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "[7 2 1 ... 4 5 6]\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 52s, sys: 2min 14s, total: 13min 6s\n",
      "Wall time: 4min 3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cnn\n",
       "Accuracy   0.9759\n",
       "Precision  0.9759\n",
       "Recall     0.9759"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# TODO n_out_channelは1しか動かない\n",
    "dnn = ScratchCNNClassifier(epoch = 7, n_padding=0, n_stride= 1, ada_grad = True, n_in_channel = 1, n_out_channel = 1, verbose=False)\n",
    "dnn.fit(X_train, y_train, X_val, y_val)\n",
    "pred_y_test = dnn.predict(X_test)\n",
    "print(pred_y_test.shape)\n",
    "print(pred_y_test)\n",
    "print(y_test)\n",
    "display_loss_graph(dnn)\n",
    "dnn_tanh_ada_grad_result = eval_accuracy(dnn, X_test, y_test, \"cnn\")\n",
    "dnn_tanh_ada_grad_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
